{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e92045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:06:49.372715Z",
     "iopub.status.busy": "2025-12-12T09:06:49.371940Z",
     "iopub.status.idle": "2025-12-12T09:10:47.393785Z",
     "shell.execute_reply": "2025-12-12T09:10:47.392172Z"
    },
    "papermill": {
     "duration": 238.028763,
     "end_time": "2025-12-12T09:10:47.395903",
     "exception": false,
     "start_time": "2025-12-12T09:06:49.367140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 09:06:53.817540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765530414.097399      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765530414.176413      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pronto\r\n",
      "  Downloading pronto-2.7.2-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: chardet~=5.0 in /usr/local/lib/python3.11/dist-packages (from pronto) (5.2.0)\r\n",
      "Collecting fastobo<0.15.0,>=0.13.0 (from pronto)\r\n",
      "  Downloading fastobo-0.14.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: networkx<4.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from pronto) (3.5)\r\n",
      "Requirement already satisfied: python-dateutil~=2.8 in /usr/local/lib/python3.11/dist-packages (from pronto) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil~=2.8->pronto) (1.17.0)\r\n",
      "Downloading pronto-2.7.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastobo-0.14.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: fastobo, pronto\r\n",
      "Successfully installed fastobo-0.14.1 pronto-2.7.2\r\n",
      "--- BƯỚC 1: Xử lý Dữ liệu & Căn chỉnh X, Y ---\n",
      "X_train_final shape: (73756, 1024), Y_train_final shape: (73756, 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 09:07:44.896768: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BƯỚC 2: Bắt đầu Huấn luyện Keras MLP ---\n",
      "Epoch 1/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - binary_accuracy: 0.9484 - loss: 0.4814 - val_binary_accuracy: 0.9970 - val_loss: 0.0256\n",
      "Epoch 2/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9969 - loss: 0.0211 - val_binary_accuracy: 0.9970 - val_loss: 0.0165\n",
      "Epoch 3/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9970 - loss: 0.0166 - val_binary_accuracy: 0.9970 - val_loss: 0.0154\n",
      "Epoch 4/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9970 - loss: 0.0159 - val_binary_accuracy: 0.9970 - val_loss: 0.0148\n",
      "Epoch 5/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - binary_accuracy: 0.9970 - loss: 0.0153 - val_binary_accuracy: 0.9970 - val_loss: 0.0145\n",
      "Epoch 6/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - binary_accuracy: 0.9970 - loss: 0.0147 - val_binary_accuracy: 0.9970 - val_loss: 0.0141\n",
      "Epoch 7/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9970 - loss: 0.0146 - val_binary_accuracy: 0.9970 - val_loss: 0.0139\n",
      "Epoch 8/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - binary_accuracy: 0.9970 - loss: 0.0143 - val_binary_accuracy: 0.9970 - val_loss: 0.0137\n",
      "Epoch 9/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - binary_accuracy: 0.9970 - loss: 0.0142 - val_binary_accuracy: 0.9970 - val_loss: 0.0135\n",
      "Epoch 10/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - binary_accuracy: 0.9971 - loss: 0.0138 - val_binary_accuracy: 0.9971 - val_loss: 0.0132\n",
      "Epoch 11/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9971 - loss: 0.0136 - val_binary_accuracy: 0.9971 - val_loss: 0.0130\n",
      "Epoch 12/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - binary_accuracy: 0.9970 - loss: 0.0135 - val_binary_accuracy: 0.9971 - val_loss: 0.0129\n",
      "Epoch 13/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9971 - loss: 0.0133 - val_binary_accuracy: 0.9971 - val_loss: 0.0128\n",
      "Epoch 14/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9971 - loss: 0.0131 - val_binary_accuracy: 0.9971 - val_loss: 0.0127\n",
      "Epoch 15/15\n",
      "\u001b[1m245/245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - binary_accuracy: 0.9971 - loss: 0.0131 - val_binary_accuracy: 0.9971 - val_loss: 0.0126\n",
      "✅ Huấn luyện hoàn thành.\n",
      "\n",
      "--- BƯỚC 3: Dự đoán và Tạo Submission ---\n",
      "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
      "Bắt đầu Chuyển đổi Định dạng và Lọc Ngưỡng...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting Predictions: 100%|██████████| 141865/141865 [00:04<00:00, 33409.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1423536 predictions from T5 model.\n",
      "\n",
      "--- BƯỚC 3.4: Kết hợp với Homology (Foldseek) ---\n",
      "Loaded 13818804 predictions from Foldseek.\n",
      "Total predictions before deduplication: 15242340\n",
      "Total predictions after deduplication (Max Blending): 14579948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "!pip install pronto\n",
    "# --- Thư viện mới cho xử lý hậu kỳ ---\n",
    "from pronto import Ontology\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ==========================================\n",
    "# 0. CẤU HÌNH VÀ ĐƯỜNG DẪN (CONFIGURATION)\n",
    "# ==========================================\n",
    "\n",
    "CONFIG = {\n",
    "    'num_classes': 1500,\n",
    "    'input_dim': 1024,\n",
    "    'test_split': 0.15,\n",
    "    'learning_rate': 1e-3, # <--- THAY ĐỔI: 1e-2 thường quá cao, 1e-3 là lựa chọn an toàn hơn\n",
    "    'epochs': 15,          # <--- THAY ĐỔI: Tăng số epochs để model học được nhiều hơn\n",
    "    'batch_size': 256,     # <--- THAY ĐỔI: Batch size lớn hơn thường giúp huấn luyện ổn định hơn\n",
    "    'dropout_rate': 0.3,   # <--- THAY ĐỔI: Tăng dropout một chút để chống overfitting\n",
    "    'score_threshold': 0.05\n",
    "}\n",
    "\n",
    "# ĐƯỜNG DẪN TẬP TRAIN\n",
    "TRAIN_TERMS_PATH = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\n",
    "TRAIN_IDS_PATH = '/kaggle/input/t5embeds/train_ids.npy'\n",
    "TRAIN_EMBEDS_PATH = '/kaggle/input/t5embeds/train_embeds.npy'\n",
    "\n",
    "# ĐƯỜNG DẪN TẬP TEST\n",
    "TEST_IDS_PATH = '/kaggle/input/t5embeds/test_ids.npy'\n",
    "TEST_EMBEDS_PATH = '/kaggle/input/t5embeds/test_embeds.npy'\n",
    "\n",
    "# --- ĐƯỜNG DẪN MỚI CHO XỬ LÝ HẬU KỲ ---\n",
    "GO_OBO_PATH = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\n",
    "HOMOLOGY_PATH = '/kaggle/input/foldseek-cafa/foldseek_submission.tsv'\n",
    "\n",
    "# ==========================================\n",
    "# 1. XỬ LÝ DỮ LIỆU VÀ CĂN CHỈNH (DATA PREPARATION & ALIGNMENT)\n",
    "# ==========================================\n",
    "# (Giữ nguyên, phần này đã rất tốt)\n",
    "print(\"--- BƯỚC 1: Xử lý Dữ liệu & Căn chỉnh X, Y ---\")\n",
    "train_terms = pd.read_csv(TRAIN_TERMS_PATH, sep=\"\\t\")\n",
    "labels_to_keep = train_terms['term'].value_counts().index[:CONFIG['num_classes']].tolist()\n",
    "train_terms_updated = train_terms.loc[train_terms['term'].isin(labels_to_keep)]\n",
    "y_train_matrix = pd.crosstab(train_terms_updated['EntryID'], train_terms_updated['term'])\n",
    "labels_final = y_train_matrix.columns.tolist()\n",
    "\n",
    "train_protein_ids = np.load(TRAIN_IDS_PATH, allow_pickle=True)\n",
    "train_embeddings = np.load(TRAIN_EMBEDS_PATH)\n",
    "X_df_raw = pd.DataFrame(train_embeddings, index=train_protein_ids)\n",
    "X_df_raw.index.name = 'EntryID'\n",
    "\n",
    "common_ids = list(set(y_train_matrix.index) & set(X_df_raw.index))\n",
    "Y_train_matrix_aligned = y_train_matrix.loc[common_ids].sort_index()\n",
    "X_df_raw_aligned = X_df_raw.loc[common_ids].sort_index()\n",
    "\n",
    "X_train_final = X_df_raw_aligned.values\n",
    "Y_train_final = Y_train_matrix_aligned.values\n",
    "print(f\"X_train_final shape: {X_train_final.shape}, Y_train_final shape: {Y_train_final.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ĐỊNH NGHĨA VÀ HUẤN LUYỆN MÔ HÌNH (MODEL & TRAINING)\n",
    "# ==========================================\n",
    "# (Giữ nguyên)\n",
    "def build_cafa_model(input_dim, num_classes, dropout_rate, learning_rate):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(input_dim,)),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation=None) \n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=['binary_accuracy'] # <--- THAY ĐỔI: 'accuracy' không phù hợp cho multi-label\n",
    "    )\n",
    "    return model\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_final, Y_train_final, test_size=CONFIG['test_split'], random_state=42\n",
    ")\n",
    "\n",
    "cafa_model = build_cafa_model(\n",
    "    CONFIG['input_dim'], CONFIG['num_classes'], CONFIG['dropout_rate'], CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "print(\"\\n--- BƯỚC 2: Bắt đầu Huấn luyện Keras MLP ---\")\n",
    "history = cafa_model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "print(\"✅ Huấn luyện hoàn thành.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. DỰ ĐOÁN VÀ SUBMISSION (INFERENCE & FORMATTING)\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- BƯỚC 3: Dự đoán và Tạo Submission ---\")\n",
    "\n",
    "# 3.1. Tải Dữ liệu Test (X_test)\n",
    "X_test_ids = np.load(TEST_IDS_PATH, allow_pickle=True)\n",
    "X_test_embeds = np.load(TEST_EMBEDS_PATH)\n",
    "\n",
    "# 3.2. Dự đoán\n",
    "test_predictions_logits = cafa_model.predict(X_test_embeds, batch_size=CONFIG['batch_size'])\n",
    "test_predictions_proba = tf.keras.activations.sigmoid(test_predictions_logits).numpy()\n",
    "\n",
    "# 3.3. Chuyển đổi sang Định dạng Submission Dài\n",
    "submission_list = []\n",
    "threshold = CONFIG['score_threshold']\n",
    "\n",
    "print(\"Bắt đầu Chuyển đổi Định dạng và Lọc Ngưỡng...\")\n",
    "for i in tqdm(range(len(X_test_ids)), desc=\"Formatting Predictions\"):\n",
    "    protein_id = X_test_ids[i]\n",
    "    predicted_indices = np.where(test_predictions_proba[i] >= threshold)[0]\n",
    "    for idx in predicted_indices:\n",
    "        go_term = labels_final[idx]\n",
    "        score = test_predictions_proba[i, idx]\n",
    "        submission_list.append([protein_id, go_term, score])\n",
    "\n",
    "df_predictions = pd.DataFrame(submission_list, columns=['ProteinID', 'GOTermID', 'Confidence'])\n",
    "print(f\"Generated {len(df_predictions)} predictions from T5 model.\")\n",
    "\n",
    "# <--- THÊM MỚI: BƯỚC 3.4 - KẾT HỢP VỚI HOMOLOGY (FOLDSEEK) ---\n",
    "print(\"\\n--- BƯỚC 3.4: Kết hợp với Homology (Foldseek) ---\")\n",
    "if os.path.exists(HOMOLOGY_PATH):\n",
    "    homology_df = pd.read_csv(HOMOLOGY_PATH, sep='\\t', header=None, names=['ProteinID', 'GOTermID', 'Confidence'])\n",
    "    print(f\"Loaded {len(homology_df)} predictions from Foldseek.\")\n",
    "    \n",
    "    # Gộp hai nguồn dự đoán\n",
    "    combined_df = pd.concat([df_predictions, homology_df], ignore_index=True)\n",
    "    print(f\"Total predictions before deduplication: {len(combined_df)}\")\n",
    "    \n",
    "    # Sắp xếp theo Confidence và loại bỏ trùng lặp, giữ lại cái có điểm cao nhất\n",
    "    combined_df = combined_df.sort_values('Confidence', ascending=False).drop_duplicates(subset=['ProteinID', 'GOTermID'], keep='first')\n",
    "    print(f\"Total predictions after deduplication (Max Blending): {len(combined_df)}\")\n",
    "else:\n",
    "    print(\"⚠️ Homology file not found. Proceeding with T5 model predictions only.\")\n",
    "    combined_df = df_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dcb14b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:10:47.632147Z",
     "iopub.status.busy": "2025-12-12T09:10:47.631788Z",
     "iopub.status.idle": "2025-12-12T09:12:51.775181Z",
     "shell.execute_reply": "2025-12-12T09:12:51.773207Z"
    },
    "papermill": {
     "duration": 124.264437,
     "end_time": "2025-12-12T09:12:51.777793",
     "exception": false,
     "start_time": "2025-12-12T09:10:47.513356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BƯỚC 3.5: Thực thi Hierarchy Propagation (Tối ưu hóa) ---\n",
      "Đang tải file go-basic.obo vào bộ nhớ...\n",
      "Đã tải thành công Ontology với 48106 terms.\n",
      "Tiền tính toán bản đồ tổ tiên cho 30743 GO terms duy nhất...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Ancestor Map: 100%|██████████| 30743/30743 [00:04<00:00, 6296.99it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bản đồ tổ tiên đã được tạo.\n",
      "Chia dữ liệu thành 4 phần và xử lý song song...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parallel Processing: 100%|██████████| 4/4 [00:00<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng hợp kết quả từ các nhân CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging results: 100%|██████████| 4/4 [00:12<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BƯỚC 3.6: Xuất file Submission ---\n",
      "\n",
      "✅ Đã tạo file submission hoàn thành tại: submission.tsv\n",
      "Tổng số dự đoán trong file submission: 16010569\n",
      "Top 5 dòng của file cuối cùng:\n",
      "      EntryID     GO Term  Score\n",
      "0  A0A3G2FQK2  GO:0140678    1.0\n",
      "1  A0A3G2FQK2  GO:0098772    1.0\n",
      "2  A0A3G2FQK2  GO:0003674    1.0\n",
      "3      P28548  GO:0043229    1.0\n",
      "4      P28548  GO:0005575    1.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. DỰ ĐOÁN VÀ SUBMISSION (INFERENCE & FORMATTING)\n",
    "# ==========================================\n",
    "def process_chunk(df_chunk, ancestor_map):\n",
    "    \"\"\"\n",
    "    Hàm này xử lý một phần nhỏ của DataFrame.\n",
    "    Nó được định nghĩa ở cấp cao nhất (global) để có thể \"pickle\".\n",
    "    \"\"\"\n",
    "    propagated_predictions = {}\n",
    "    # Sử dụng itertuples() nhanh hơn nhiều so với iterrows()\n",
    "    for row in df_chunk.itertuples(index=False):\n",
    "        protein_id, term_id, confidence = row.ProteinID, row.GOTermID, row.Confidence\n",
    "\n",
    "        # Thêm dự đoán gốc\n",
    "        key = (protein_id, term_id)\n",
    "        if key not in propagated_predictions or confidence > propagated_predictions[key]:\n",
    "            propagated_predictions[key] = confidence\n",
    "        \n",
    "        # Lấy các tổ tiên từ bản đồ đã tính toán trước\n",
    "        if term_id in ancestor_map:\n",
    "            for ancestor_id in ancestor_map[term_id]:\n",
    "                ancestor_key = (protein_id, ancestor_id)\n",
    "                if ancestor_key not in propagated_predictions or confidence > propagated_predictions[ancestor_key]:\n",
    "                    propagated_predictions[ancestor_key] = confidence\n",
    "                    \n",
    "    return propagated_predictions\n",
    "\n",
    "# --- BƯỚC 3.5: THỰC THI PHÂN CẤP GO (PHIÊN BẢN TỐI ƯU) ---\n",
    "print(\"\\n--- BƯỚC 3.5: Thực thi Hierarchy Propagation (Tối ưu hóa) ---\")\n",
    "\n",
    "def apply_hierarchy_enforcement_optimized(df):\n",
    "    print(\"Đang tải file go-basic.obo vào bộ nhớ...\")\n",
    "    with open(GO_OBO_PATH, 'rb') as f:\n",
    "        go = Ontology(f)\n",
    "    print(f\"Đã tải thành công Ontology với {len(go)} terms.\")\n",
    "\n",
    "    unique_terms = df['GOTermID'].unique()\n",
    "    print(f\"Tiền tính toán bản đồ tổ tiên cho {len(unique_terms)} GO terms duy nhất...\")\n",
    "\n",
    "    term_ancestors_map = {}\n",
    "    for term_id in tqdm(unique_terms, desc=\"Building Ancestor Map\"):\n",
    "        try:\n",
    "            term = go[term_id]\n",
    "            ancestors = {ancestor.id for ancestor in term.superclasses() if ancestor.id != term_id}\n",
    "            term_ancestors_map[term_id] = ancestors\n",
    "        except KeyError:\n",
    "            term_ancestors_map[term_id] = set()\n",
    "    print(\"Bản đồ tổ tiên đã được tạo.\")\n",
    "\n",
    "    n_jobs = os.cpu_count()\n",
    "    print(f\"Chia dữ liệu thành {n_jobs} phần và xử lý song song...\")\n",
    "    df_chunks = np.array_split(df, n_jobs)\n",
    "    \n",
    "    parallel = Parallel(n_jobs=n_jobs, backend='multiprocessing')\n",
    "    # Bây giờ chúng ta gọi hàm global `process_chunk` và truyền `term_ancestors_map` vào\n",
    "    results_list = parallel(delayed(process_chunk)(chunk, term_ancestors_map) for chunk in tqdm(df_chunks, desc=\"Parallel Processing\"))\n",
    "\n",
    "    print(\"Tổng hợp kết quả từ các nhân CPU...\")\n",
    "    final_propagated_predictions = {}\n",
    "    for chunk_dict in tqdm(results_list, desc=\"Merging results\"):\n",
    "        for key, value in chunk_dict.items():\n",
    "            if key not in final_propagated_predictions or value > final_propagated_predictions[key]:\n",
    "                final_propagated_predictions[key] = value\n",
    "\n",
    "    final_list = [{'ProteinID': k[0], 'GOTermID': k[1], 'Confidence': v} for k, v in final_propagated_predictions.items()]\n",
    "    return pd.DataFrame(final_list)\n",
    "\n",
    "df_submission_final = apply_hierarchy_enforcement_optimized(combined_df)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# 3.6. Xuất Submission\n",
    "print(\"\\n--- BƯỚC 3.6: Xuất file Submission ---\")\n",
    "df_submission_final['Confidence'] = df_submission_final['Confidence'].round(4)\n",
    "# Đổi tên cột để khớp với yêu cầu (nếu cần)\n",
    "df_submission_final = df_submission_final.rename(columns={'ProteinID': 'EntryID', 'GOTermID': 'GO Term', 'Confidence': 'Score'})\n",
    "\n",
    "SUBMISSION_FILE_PATH = 'submission.tsv'\n",
    "df_submission_final[['EntryID', 'GO Term', 'Score']].to_csv(\n",
    "    SUBMISSION_FILE_PATH, \n",
    "    sep='\\t', \n",
    "    header=False, \n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Đã tạo file submission hoàn thành tại: {SUBMISSION_FILE_PATH}\")\n",
    "print(f\"Tổng số dự đoán trong file submission: {len(df_submission_final)}\")\n",
    "print(\"Top 5 dòng của file cuối cùng:\")\n",
    "print(df_submission_final.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 3167603,
     "sourceId": 5499219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8688768,
     "sourceId": 13665986,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8699749,
     "sourceId": 13680623,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3458902,
     "sourceId": 6046570,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 371.688696,
   "end_time": "2025-12-12T09:12:55.330677",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T09:06:43.641981",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
